## 前提

- テスト対象は `initializeRaftKv` で初期化される Raft ノード(単体/複数)。
- テスト用にモック/フェイク実装した `RaftKvRpc` や `RaftKvStorage`、あるいはタイマー (heartbeatInterval, electionTimeout, など) を利用して制御する想定。
- すべてのメソッドを正しく呼び出し、返される状態 (`getNodeState()`) や返り値を確認する。

---

# 1. ノードの初期状態に関するテスト

### 1-1: フォロワーとして初期化されることの確認

- **シナリオ**
  1. シングルノードまたは複数ノードで `initializeRaftKv` を呼び出す。
  2. `getNodeState()` を確認する。
- **期待結果**
  - `role` が `"follower"` である。
  - `commitIndex` が 0。
  - 初期 `term` が 0。
  - `votedFor` が `null` である(未投票)。

### 1-2: `storage` にデータがあった場合の初期化

- **シナリオ**
  1. ストレージ内に既に term, votedFor, ログなどが存在する状態をエミュレートする。
  2. `initializeRaftKv` を呼び出す。
  3. `getNodeState()` の結果を確認する。
- **期待結果**
  - ストレージにあった term / votedFor / ログが正しく読み込まれている。
  - `role` は `"follower"` になっている (Raft は再起動時は基本的に follower から始まる想定)。

---

# 2. 選挙に関するテスト

### 2-1: タイムアウトによりフォロワーが候補者に昇格

- **シナリオ**
  1. 3 ノードのクラスタを想定。すべてフォロワー状態にする。
  2. メインのノード(A)に対して、ハートビートが来ない状態をシミュレートする。
  3. `electionTimeout` のコールバックを強制的に発火させる。
  4. ノード A が `role: "candidate"` になるかを確認する。
- **期待結果**
  - ノード A が候補者になり、term が 1 増える。
  - `votedFor` が自分自身 (A の nodeId) になっている。

### 2-2: 過半数の票を得てリーダーになる

- **シナリオ**
  1. 3 ノードのクラスタ (A, B, C) を用意し、A が候補者になった直後を想定。
  2. A が B, C へ `requestVote` を送信。
  3. B, C は投票を許可する (voteGranted = true)。
  4. A が過半数(2 票以上)を獲得したタイミングで `role: "leader"` に切り替わるか確認。
- **期待結果**
  - ノード A がリーダーになり、`role` が `"leader"`。
  - `term` が正しい値(例えば 1 からスタートして +1 で 2 など)。
  - `votedFor` は引き続き A である。

### 2-3: 他ノードがより高い term で選挙を仕掛けてきた場合

- **シナリオ**
  1. ノード A がリーダーまたは候補者になっている。
  2. ノード B からもっと高い term(例えば A=2 に対して B=3) で AppendEntries or RequestVote が呼ばれる。
  3. A がフォロワーに降格し、term を更新するか確認。
- **期待結果**
  - A の `role` が `"follower"` に変更される。
  - A の term が 3 に更新される。
  - `votedFor` が `null` に戻る(または B に投票する場合もあるが、それは RequestVoteArgs 次第)。

### 2-4: 投票拒否の条件(ログが古い, すでに投票済み)

- **シナリオ**
  1. ノード A のログが最新なのに、ノード B が古いログ状態で `RequestVote` を要求する。
  2. A のほうがログが「新しい」ため、B に投票せず。
  3. 同じ term の中で既に投票先が決まっている場合にも投票拒否。
- **期待結果**
  - `voteGranted = false` で返される。
  - A の `votedFor` に変化がない(または既に `votedFor` が A だったり)。

### 2-5: タイムアウト時の再選挙

- **シナリオ**
  1. A が candidate になり RequestVote を送るが、過半数を得られない (B からは投票を得たが C がダウンなど)。
  2. 選挙タイムアウトが発生。
  3. A は再度 term を増加させて candidate になり、再度投票を要求するシナリオ。
- **期待結果**
  - タイムアウトするたびに `term` が +1 される。
  - 最終的に過半数が得られればリーダーになり、得られなければフォロワーへ降格などの状態遷移が正しく行われる。

---

# 3. リーダー時のハートビートに関するテスト

### 3-1: リーダーが定期的にハートビートを送る

- **シナリオ**
  1. A がリーダーになった状態からスタート。
  2. `heartbeatInterval(cb)` のコールバック (`_sendHeartbeat`) を発火。
  3. 各ノード(B, C) に空の `AppendEntries` が送信されるか確認。
- **期待結果**
  - B, C は受領した `AppendEntries` のレスポンスとして `success = true` を返す(ログ不一致がない限り)。
  - A は role: "leader" を維持し続ける。
  - 受信した B, C は自分の選挙タイムアウトをリセットしてフォロワーで居続ける。

### 3-2: リーダーがハートビートに対してレスポンスの term が高い場合、フォロワーに降格

- **シナリオ**
  1. A がリーダーだが、なぜか B が term を上げてしまった (たとえば B が別のクラスタで選挙を行い、より高い term を獲得)。
  2. ハートビートに対して B が `term > A.term` で応答。
  3. A がリーダーを放棄してフォロワーに降格するかを確認。
- **期待結果**
  - A の `role` が `"follower"` に変わり、term も B に合わせた値に更新される。

---

# 4. ログの追随(レプリケーション)に関するテスト

### 4-1: クライアントコマンドをリーダーに投げてレプリケーション

- **シナリオ**
  1. A がリーダーのとき、クライアントから 1 つの書き込みコマンド(`KvCommand`)を `handleClientRequest` する。
  2. `_appendAndCommitCommands` が呼ばれ、B, C へ `AppendEntries` が送られる。
  3. 過半数承認を得たら `commitIndex` がインクリメントされる。
- **期待結果**
  - リーダー(A)のローカルログに新しいコマンドが追記される。
  - B, C にも同じログが追記される。
  - 過半数が受領し、`commitIndex` が更新される。
  - `storage.commitLogEntries(commitIndex)` が呼ばれ、実際に State Machine へ反映される(確認方法はストレージモックなどで検証)。

### 4-2: ログ不一致の修正 (AppendEntries 失敗 → 一つ前のインデックスを再送)

- **シナリオ**
  1. リーダー(A)とフォロワー(B) の間でログがずれている状態を作る (B が古いログを持つなど)。
  2. A が B に `AppendEntries` を送るが、`prevLogIndex` / `prevLogTerm` が合わないため失敗 (`success = false`)。
  3. A は `nextIndex` をデクリメントして再送を行い、正しいログを B に与える。
- **期待結果**
  - A はログ不一致のたびに `nextIndex` を 1 ずつ下げて再送。
  - B は適切な位置からログを追記し、一致したところから最後までを受け取る。
  - 最終的に B のログが A と同一になる。

### 4-3: 過半数未満しか応答が無い場合のコミット不可

- **シナリオ**
  1. A がリーダーで、B は正常応答するが C がネットワークダウン(タイムアウト)を想定する。
  2. A はクライアントコマンドをログに追記し B に送信するが、C から応答が来ない。
  3. 過半数が取れないためコミットできない。
- **期待結果**
  - 2/3 ノードの承認は 1 ノードだけ(B)なので過半数 (2 ノード) に届かない。
  - `commitIndex` が進まない。
  - ストレージ上の `commitLogEntries` は呼ばれない。

### 4-4: 空エントリ(no-op)のレプリケーション

- **シナリオ**
  1. リーダー就任時に `void _appendAndCommitCommands([{ op: "noop" }]);` が呼ばれる箇所がある。
  2. 実際にその no-op がログに入り、全 follower に送信されるか確認。
  3. 過半数が受領したらコミットされるかを確認。
- **期待結果**
  - ログに no-op (空操作のコマンド) が記録される。
  - 過半数承認で `commitIndex` が進む。
  - State Machine によっては実際の操作は何もしないが、コミット動作自体は行われる。

---

# 5. フォロワーでの AppendEntries 処理に関するテスト

### 5-1: leaderCommit より先のログは適用しない

- **シナリオ**
  1. フォロワー(B) がリーダー(A) からログを受け取り、`AppendEntries` の引数に `leaderCommit = x` とある。
  2. B のローカルログでは `x` よりも先(高い index) のログを持っている(不整合状態)場合。
  3. B は `commitIndex` を `min(leaderCommit, 最後に受け取ったログの index)` に設定して適用するか確認。
- **期待結果**
  - B は指定された `leaderCommit` の位置までしか commit しない。
  - B に余計なログがあれば、(term 違いなどで) 将来的にリーダーから上書きされる可能性がある。

### 5-2: prevLogTerm が一致しない場合の拒否

- **シナリオ**
  1. B が `AppendEntries` を受信したが、`args.prevLogIndex` のログの term が食い違う。
  2. B は `success = false` を返す。
- **期待結果**
  - B のログにおける `prevLogIndex` と `prevLogTerm` が合わないので、フォロワーは応答を `success = false` とする。
  - リーダー(A)はその応答を見て `nextIndex` を下げて再送を行う。

### 5-3: leaderCommit 分まで State Machine に適用する

- **シナリオ**
  1. B が `AppendEntries`(エントリ多数) を受信して、`leaderCommit` がそのログインデックスより先にある。
  2. 例えば、`leaderCommit = 5` で、今回受信するログの末尾が `index = 5` まで。
  3. B は index=5 までコミットし、`storage.commitLogEntries(5)` を呼ぶか確認。
- **期待結果**
  - 実際に B のストレージの `commitLogEntries(5)` が呼ばれ、State Machine に反映される。
  - B の `commitIndex` = 5 となる。

---

# 6. クライアントリクエストに関するテスト

### 6-1: フォロワーへのクライアントリクエストはリダイレクトされる

- **シナリオ**
  1. A, B, C のクラスタで A がリーダー。
  2. フォロワー(B) に対して `handleClientRequest([...])` を呼ぶ。
  3. B は `role: "follower"` なので `{ type: "redirect", redirect: ??? }` を返す。
- **期待結果**
  - リダイレクト先として `votedFor` (またはリーダーの `nodeId`) が返される(実装依存)。
  - 実際に B はクライアントリクエストを処理しない。

### 6-2: 選挙中のクライアントリクエストは「in-election」を返す

- **シナリオ**
  1. A がまだリーダー確定しておらず、`role: "candidate"` 状態のときに `handleClientRequest([...])` を呼ぶ。
  2. A は `role: "candidate"` なので `{ type: "in-election" }` を返す。
- **期待結果**
  - リクエストが受理されず、クライアントは再送などの別対処を行う流れを確認。

### 6-3: リーダーへのクライアントリクエストが成功し、ログおよびコミットまで行われる

- **シナリオ**
  1. A がリーダー。
  2. `handleClientRequest([{ op: "put", key: "x", value: 1 }])` のようなコマンドを送る。
  3. 内部で `_appendAndCommitCommands` が呼ばれ、過半数が承認しコミットされる。
  4. `{ type: "success" }` が返る。
- **期待結果**
  - A, B, C のログに `op: "put", key: "x", value: 1` のエントリが含まれ、一致する。
  - `commitIndex` が増加し、State Machine に `{"x": 1}` のような状態変更が適用される(ストレージ経由で検証)。
  - レスポンスが `{ type: "success" }`。

---

# 7. タイムアウト・リトライに関するテスト

### 7-1: `appendEntriesTimeout` による再送

- **シナリオ**
  1. リーダー(A) が B に `AppendEntries` を送ったが、B がタイムアウトして応答が無い。
  2. `appendEntriesTimeout().then(() => null)` によって `result` が null になる処理が発動。
  3. A は `await _sendAppendEntries(node, args)` をリトライする。
- **期待結果**
  - A が何度か再送を試みる(内部的に無限ループしないように注意)。
  - B が復帰したタイミングで `success = true` となりログが同期される。

### 7-2: `electionRetrySleep` による選挙の再試行

- **シナリオ**
  1. A が選挙を始めたが十分な票を得られない or タイムアウトが発生。
  2. `_startElection` 内部で `timers.electionRetrySleep()` が呼ばれる想定。
  3. 再度 `_startElection()` がコールされるまでの時間をモックして確認。
- **期待結果**
  - A の term がインクリメントし、再度投票要求を行う。
  - 過半数を獲得できるまで繰り返すか、あるいは他ノードのリーダーを検出すればフォロワーに戻る。

---

# 8. 障害・ネットワーク分断シナリオに関するテスト

### 8-1: リーダーのクラッシュとフォロワーの昇格

- **シナリオ**
  1. A, B, C で A がリーダー。B, C はフォロワー。
  2. A がクラッシュ(全 API が反応しなくなる)。
  3. B, C が A からハートビートを受け取れず、選挙タイムアウト。
  4. B または C が候補者になり、過半数を確保したほうが新リーダーになる。
- **期待結果**
  - A 以外のノードが新リーダーを自発的に選出。
  - クラッシュした A は復帰しない限りリーダーに戻れない。

### 8-2: ネットワーク分断でリーダーが 2 台になりかける状況

- **シナリオ**
  1. A, B, C で A がリーダー。
  2. ネットワーク分断で B, C と A の間が切断。B, C 同士は通信可能。
  3. B, C は A のハートビートを受け取れなくなる → 選挙開始。
  4. B がリーダーになったとする。
  5. しばらくしてネットワークが復旧し、A と B が互いに高い term / 低い term の AppendEntries を送る。
- **期待結果**
  - A は B の term が高ければフォロワーに降格。
  - または B のほうが低い term なら B がフォロワーになる(ただし通常はネット分断先での選挙により term が上がるため B が高い term を持つはず)。
  - 最終的にクラスタは単一のリーダーに収束する。

---

# 9. ストレージ/ロックまわりに関するテスト

### 9-1: `createLock()` による排他制御

- **シナリオ**
  1. `handleAppendEntries` や `handleRequestVote` を並行で呼んでみる (モック RPC で同時に呼ぶ)。
  2. ロックが正しく順番に処理を保証しているかを検証。
- **期待結果**
  - データ競合が起こらず、ログの整合性が保たれる。
  - ロックの獲得/解放が正しく行われ、デッドロックに陥らない。

### 9-2: ストレージとの整合確認

- **シナリオ**
  1. ログや term, votedFor の保存・読み込みフローをモックしたストレージで検証。
  2. `_becomeFollower` / `_becomeLeader` / `_appendAndCommitCommands` / `handleAppendEntries` などのたびに、ストレージの値が正しいか確認。
- **期待結果**
  - メモリ上の `term`, `votedFor`, ログインデックスとストレージに保存されている値が一致する。
  - コミット操作(`commitLogEntries`)が呼ばれた際には、ログの一部または全部が「コミット済み」扱いになる。

---
